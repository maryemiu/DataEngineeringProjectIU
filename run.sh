#!/usr/bin/env bash
##############################################################################
# run_all.sh â€” Full Bootstrap Script
# Runs the entire system from scratch to a live API in one command.
#
# Pipeline:
#   1. Pre-flight checks
#   2. Create Docker network (uni_net)
#   3. Build all Docker images
#   4. Start HDFS (Storage Layer)
#   5. Start PostgreSQL (Serving Store)
#   6. Run Ingestion (initial load â†’ HDFS raw zone)
#   7. Run Processing (feature engineering + similarity â†’ HDFS curated zone)
#   8. Run Recommendation Loader (HDFS curated â†’ PostgreSQL)
#   9. Start Recommendation API
#  10. Verify & print summary
#
# Usage:
#   bash run_all.sh
#
# Requirements:
#   - Docker Desktop running
#   - Docker Compose v2.20+
#   - .env file present (copy from .env.example)
#   - data/EdNet-KT4/ and data/EdNet-Contents/ populated
#     (see docs/DATA_SETUP.md)
#
# All timestamps are UTC. Exits on any step failure.
##############################################################################

set -euo pipefail

# â”€â”€ Colors â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
CYAN='\033[0;36m'
BOLD='\033[1m'
NC='\033[0m' # No Color

# â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

log()     { echo -e "${CYAN}[$(date -u +"%Y-%m-%dT%H:%M:%SZ")]${NC} $*"; }
success() { echo -e "${GREEN}[$(date -u +"%Y-%m-%dT%H:%M:%SZ")] âœ”  $*${NC}"; }
warn()    { echo -e "${YELLOW}[$(date -u +"%Y-%m-%dT%H:%M:%SZ")] âš   $*${NC}"; }
fail()    { echo -e "${RED}[$(date -u +"%Y-%m-%dT%H:%M:%SZ")] âœ˜  ERROR: $*${NC}"; exit 1; }

header() {
  echo ""
  echo -e "${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
  echo -e "${BOLD}  $*${NC}"
  echo -e "${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
}

wait_for_healthy() {
  local service="$1"
  local max_wait="${2:-120}"
  local elapsed=0
  log "Waiting for '${service}' to become healthy (max ${max_wait}s) â€¦"
  while [ "$elapsed" -lt "$max_wait" ]; do
    local status
    status=$(sudo docker inspect --format='{{.State.Health.Status}}' "$service" 2>/dev/null || echo "missing")
    if [ "$status" = "healthy" ]; then
      success "'${service}' is healthy."
      return 0
    fi
    sleep 5
    elapsed=$(( elapsed + 5 ))
    log "  â€¦ still waiting for '${service}' (${elapsed}s / ${max_wait}s, status: ${status})"
  done
  fail "'${service}' did not become healthy within ${max_wait}s."
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Start
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

TOTAL_START=$(date -u +%s)

header "University Recommendation System â€” Full Bootstrap"
log "Start time: $(date -u)"

# â”€â”€ Step 1 â€” Pre-flight Checks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

header "Step 1 / 9 â€” Pre-flight Checks"

# .env file
if [ ! -f ".env" ]; then
  fail ".env file not found. Copy .env.example â†’ .env and fill in secrets."
fi
success ".env file found."

# Docker
if ! sudo docker info > /dev/null 2>&1; then
  fail "Docker is not running."
fi
success "Docker is running."

# Docker Compose version (need v2.20+ for include:)
COMPOSE_VERSION=$(sudo docker compose version --short 2>/dev/null || echo "0.0.0")
COMPOSE_MAJOR=$(echo "$COMPOSE_VERSION" | cut -d. -f1)
COMPOSE_MINOR=$(echo "$COMPOSE_VERSION" | cut -d. -f2)
if [ "$COMPOSE_MAJOR" -lt 2 ] || { [ "$COMPOSE_MAJOR" -eq 2 ] && [ "$COMPOSE_MINOR" -lt 20 ]; }; then
  warn "Docker Compose ${COMPOSE_VERSION} detected. v2.20+ is recommended for the include: directive."
  warn "Upgrade: https://docs.docker.com/compose/install/"
else
  success "Docker Compose ${COMPOSE_VERSION} â€” OK."
fi

# Dataset
# Dataset folders â€” must exist and contain CSV files (not just .gitkeep)
if [ ! -d "data/EdNet-KT4" ]; then
  fail "data/EdNet-KT4/ folder is missing. See docs/DATA_SETUP.md."
fi
if [ ! -d "data/EdNet-Contents" ]; then
  fail "data/EdNet-Contents/ folder is missing. See docs/DATA_SETUP.md."
fi

KT4_CSV_COUNT=$(find "data/EdNet-KT4" -name "*.csv" 2>/dev/null | wc -l)
CONTENTS_CSV_COUNT=$(find "data/EdNet-Contents" -name "*.csv" 2>/dev/null | wc -l)

if [ "$KT4_CSV_COUNT" -eq 0 ] || [ "$CONTENTS_CSV_COUNT" -eq 0 ]; then
  warn "Dataset folders exist but contain no CSV files."
  warn "  data/EdNet-KT4/      â†’ ${KT4_CSV_COUNT} CSV file(s) found"
  warn "  data/EdNet-Contents/ â†’ ${CONTENTS_CSV_COUNT} CSV file(s) found"
  warn "The ingestion step WILL FAIL without real data. See docs/DATA_SETUP.md."
  warn "Continuing so you can verify infrastructure (HDFS, PostgreSQL, API) â€¦"
else
  success "Dataset folders found (KT4: ${KT4_CSV_COUNT} files, Contents: ${CONTENTS_CSV_COUNT} files)."
fi

# â”€â”€ Step 2 â€” Docker Network â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

header "Step 2 / 9 â€” Docker Network"

if sudo docker network inspect uni_net > /dev/null 2>&1; then
  success "Network 'uni_net' already exists â€” skipping creation."
else
  log "Creating Docker network 'uni_net' â€¦"
  sudo docker network create uni_net
  success "Network 'uni_net' created."
fi

# â”€â”€ Step 2.5 â€” Tear Down Any Stale Containers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Force-remove every named container individually.
# Using docker rm -f is more reliable than 'docker compose down' when containers
# are defined across multiple included compose files (project-scope mismatch
# causes compose down to silently miss some of them).

header "Step 2.5 â€” Cleaning Up Stale Containers"

KNOWN_CONTAINERS=(
  namenode datanode1 datanode2 datanode3
  postgres
  ingestion processing
  recommendation_loader recommendation_api
)

log "Force-removing any leftover containers from a previous run â€¦"
for c in "${KNOWN_CONTAINERS[@]}"; do
  if sudo docker inspect "$c" > /dev/null 2>&1; then
    sudo docker rm -f "$c" > /dev/null 2>&1 && log "  Removed: $c" || warn "  Could not remove: $c"
  fi
done 
success "Cleanup done â€” starting fresh."

# â”€â”€ Step 3 â€” Build All Images â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

header "Step 3 / 9 â€” Building Docker Images"

log "Building all microservice images â€¦"
sudo docker compose build \
  ingestion \
  processing \
  recommendation_loader \
  recommendation_api
success "All images built." 

# â”€â”€ Step 4 â€” Start Storage Layer (HDFS) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

header "Step 4 / 9 â€” Starting Storage Layer (HDFS)"

log "Starting NameNode and DataNodes â€¦"
sudo docker compose up -d namenode datanode1 datanode2 datanode3

wait_for_healthy namenode 180

success "HDFS cluster is up. Web UI: http://localhost:9870"

# â”€â”€ Step 5 â€” Start PostgreSQL â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

header "Step 5 / 9 â€” Starting PostgreSQL (Serving Store)"

log "Starting PostgreSQL â€¦"
sudo docker compose up -d postgres

wait_for_healthy postgres 60

success "PostgreSQL is up on port 5432."

# â”€â”€ Step 5b â€” HDFS directory provisioning â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

header "Step 5b / 9 â€” HDFS Directory Provisioning"

log "Creating HDFS base directories and setting permissions â€¦"
sudo docker exec namenode bash -c "hdfs dfsadmin -safemode wait && hdfs dfs -mkdir -p /data/raw/kt4 && hdfs dfs -mkdir -p /data/raw/content && hdfs dfs -mkdir -p /data/curated && hdfs dfs -chmod -R 777 /data" \
  || fail "HDFS directory provisioning failed."

success "HDFS /data hierarchy created with open permissions."

# â”€â”€ Step 6 â€” Ingestion (Initial Load) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

header "Step 6 / 9 â€” Ingestion (Initial Load â†’ HDFS Raw Zone)"

log "Running ingestion in MODE=initial â€¦"
sudo docker compose run --rm \
  -e MODE=initial \
  ingestion \
  || fail "Ingestion failed. Check logs: sudo docker compose logs ingestion"

success "Ingestion complete. Data written to HDFS /data/raw/"

log "Verifying HDFS kt4 path was written â€¦"
sudo docker exec namenode bash -c "hdfs dfs -ls /data/raw/kt4/partitions_by_event_date" \
  || fail "HDFS kt4 path not found after ingestion. Check ingestion logs for validation errors."
success "HDFS kt4 data confirmed."

# â”€â”€ Step 7 â€” Processing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

header "Step 7 / 9 â€” Processing (Feature Engineering + Similarity â†’ HDFS Curated)"

log "Running processing in MODE=initial â€¦"
sudo docker compose run --rm \
  -e MODE=initial \
  processing \
  || fail "Processing failed. Check logs: sudo docker compose logs processing"

success "Processing complete. Vectors + recommendations written to HDFS /data/curated/"

# â”€â”€ Step 8 â€” Recommendation Loader (HDFS â†’ PostgreSQL) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

header "Step 8 / 9 â€” Recommendation Loader (HDFS Curated â†’ PostgreSQL)"

log "Running recommendation_loader in MODE=initial â€¦"
sudo docker compose run --rm \
  -e MODE=initial \
  recommendation_loader \
  || fail "Recommendation loader failed. Check logs: sudo docker compose logs recommendation_loader"

success "Recommendations loaded into PostgreSQL."

# â”€â”€ Step 9 â€” Start Recommendation API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

header "Step 9 / 9 â€” Starting Recommendation API"

log "Starting recommendation_api â€¦"
sudo docker compose up -d recommendation_api

wait_for_healthy recommendation_api 60

success "API is up."

# â”€â”€ Done â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

TOTAL_END=$(date -u +%s)
TOTAL_DURATION=$(( TOTAL_END - TOTAL_START ))
MINUTES=$(( TOTAL_DURATION / 60 ))
SECONDS=$(( TOTAL_DURATION % 60 ))

echo ""
echo -e "${GREEN}${BOLD}"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "  ğŸ‰  System is fully operational!"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo "  HDFS Web UI  â†’ http://localhost:9870"
echo ""
echo "  API endpoints (replace u1 with any valid user ID):"
echo ""
echo "    # Health check"
echo "    GET http://localhost:8000/health"
echo ""
echo "    # Get top-10 recommendations for a user"
echo "    GET http://localhost:8000/recommendations/u1"
echo ""
echo "    # Get top-5 recommendations"
echo "    GET http://localhost:8000/recommendations/u1?top_k=5"
echo ""
echo "    # Get aggregated learning features for a user"
echo "    GET http://localhost:8000/students/u1/features"
echo ""
echo "  Total time: ${MINUTES}m ${SECONDS}s"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo -e "${NC}"
echo ""
log "To run the daily incremental pipeline:"
echo "  bash orchestration/scheduler/scripts/daily_pipeline/run_daily_pipeline.sh"
echo ""
log "To stop everything:"
echo "  sudo docker compose down"
echo ""

exit 0
